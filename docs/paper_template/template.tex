\documentclass{article}
\usepackage{graphicx}
\usepackage[english,russian]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{longtable}
\usepackage{pdflscape}
\setcounter{secnumdepth}{3}
\usepackage{threeparttable}
\newcommand{\norm}[1]{\left|#1\right|}

\title{Оценка устойчивости агентных систем на основе больших языковых моделей к атакам на среду исполнения}
\author{ITMO Security Lab}
\date{Декабрь 2025}

\begin{document}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Abstract}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Агентные системы на основе больших языковых моделей (LLM) всё шире применяются для автоматизации сложных задач, однако их безопасность в реалистичных сценариях взаимодействия остаётся недостаточно изученной. Существующие бенчмарки оценивают либо изолированные способности агентов, либо устойчивость к prompt injection в упрощённых условиях, не учитывая динамику взаимодействия с активным пользователем. В данной работе предлагается расширение бенчмарка $\tau^2$-bench тремя новыми доменами безопасности: \texttt{mail\_rag\_phishing} (атаки через отравление RAG-системы), \texttt{collab} (атаки через межагентное взаимодействие) и \texttt{output\_handling} (некорректная обработка выводов). Домены покрывают угрозы уровней 1--5 фреймворка AI-SAFE и соответствуют классификации OWASP LLM Top~10 и AI Agents Top~15.

Эксперименты с моделями GPT-4o и GPT-4o-mini при варьировании температуры пользовательской модели ($T_{\text{user}}\in\{0.0,0.5,1.0\}$) показывают, что сравнение устойчивости зависит от домена: в \texttt{mail\_rag\_phishing} GPT-4o статистически значимо превосходит GPT-4o-mini при всех значениях $T$ (см. табл.~\ref{tab:significance}), тогда как в \texttt{collab} и \texttt{output\_handling} статистически значимых различий по имеющимся данным не выявлено. При этом даже наилучшие конфигурации сохраняют ненулевой ASR, что указывает на необходимость специализированных защитных механизмов для агентных архитектур.

% TODO: После получения финальных результатов обновить количественные показатели (процент устойчивости, число прогонов, статистическую значимость).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Контекст и постановка задачи}

Развитие больших языковых моделей (LLM) и их интеграция в агентные системы открывает новые возможности для автоматизации сложных задач. ИИ-агенты способны к автономному планированию, взаимодействию с внешними инструментами (API, базы данных, файловые системы) и принятию решений в реальном времени~\cite{ai_safe_2025}. Однако эти же свойства создают принципиально новые поверхности атак, не характерные для классических систем машинного обучения.

Типовой ИИ-агент включает следующие компоненты~\cite{ai_safe_2025}:
\begin{itemize}
    \item \textbf{LLM} --- центральный компонент для понимания инструкций и генерации ответов;
    \item \textbf{Модуль планирования} --- преобразует высокоуровневые цели в последовательность действий;
    \item \textbf{Память} --- краткосрочная (контекст диалога) и долгосрочная (RAG-системы, базы знаний);
    \item \textbf{Инструменты} --- внешние API и функции для взаимодействия с реальным миром;
    \item \textbf{Интерфейс} --- точка входа для пользовательских запросов.
\end{itemize}

Каждый из этих компонентов представляет потенциальный вектор атаки. Фреймворк AI-SAFE~\cite{ai_safe_2025} систематизирует угрозы по пяти уровням: интерфейс (Prompt Injection, DoS), исполнение и инструменты (Tool Misuse, Privilege Escalation), инфраструктура и оркестрация (Cross-Agent Poisoning), ядро и логика (Jailbreaking, Goal Manipulation), данные и знания (RAG Poisoning, Data Leakage).

\subsection{Недостаточность существующих методов}

Современные бенчмарки для оценки безопасности агентных систем имеют существенные ограничения:

\begin{enumerate}
    \item \textbf{Изолированная оценка.} Большинство бенчмарков (AgentBench~\cite{agent_bench}, Agent Security Bench~\cite{asb}) оценивают агента в условиях монопольного контроля, где пользователь является пассивным источником инструкций.
    
    \item \textbf{Упрощённые сценарии атак.} Agent Dojo~\cite{agent_dojo} фокусируется на prompt injection в контексте одиночного агента без учёта межагентного взаимодействия и RAG-систем.
    
    \item \textbf{Отсутствие активного пользователя.} Исследования $\tau$-bench~\cite{tau_bench_2024} и $\tau^2$-bench~\cite{tau2_bench_2025} продемонстрировали, что введение активного пользователя (dual-control) приводит к падению производительности агентов до 25 процентных пунктов. Это указывает на то, что координация и коммуникация становятся критическими точками отказа, однако существующие бенчмарки безопасности не учитывают эту динамику.
\end{enumerate}

\subsection{Вклад работы (Contributions)}

В данной работе мы делаем следующий вклад:

\begin{enumerate}
    \item \textbf{Новые домены безопасности.} Разработаны три домена для бенчмарка $\tau^2$-bench, моделирующие типовые векторы атак: отравление RAG (\texttt{mail\_rag\_phishing}), межагентное взаимодействие (\texttt{collab}), некорректная обработка выводов (\texttt{output\_handling}).
    
    \item \textbf{Методика оценки в парадигме dual-control.} Предложена методика оценки устойчивости агентов к атакам с учётом активного пользователя, формализованная в рамках Dec-POMDP.
    
    \item \textbf{Эмпирическая оценка.} Проведены эксперименты с моделями GPT-4o и GPT-4o-mini, демонстрирующие существенные различия в устойчивости к различным классам атак.
    
    % TODO: После получения финальных результатов добавить количественный вклад (например, "показано, что модели размера X демонстрируют на Y% более высокую устойчивость").
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related Work}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Бенчмарки для оценки агентных систем}

Развитие LLM-агентов привело к созданию серии бенчмарков для оценки их способностей. AgentBench~\cite{agent_bench} оценивает агентов в восьми средах, включая операционные системы, базы данных и веб-навигацию, однако фокусируется на функциональных способностях без учёта безопасности. ToolBench и API-Bank исследуют использование инструментов, но в условиях доверенной среды.

Ключевым прорывом стала серия $\tau$-bench~\cite{tau_bench_2024} и $\tau^2$-bench~\cite{tau2_bench_2025}, где пользователь моделируется как активный участник, способный изменять состояние среды. Формализация в рамках Dec-POMDP~\cite{amato_2013} показала, что координация с пользователем является критическим узким местом: даже передовые модели теряют до 25 п.п. производительности при переходе от монопольного к двойному управлению.

\subsection{Оценка безопасности LLM-агентов}

Agent Security Bench (ASB)~\cite{asb} формализует атаки и защиты для LLM-агентов, однако ограничивается сценариями с одиночным агентом. Agent Dojo~\cite{agent_dojo} создаёт динамическую среду для оценки prompt injection атак, демонстрируя, что современные агенты уязвимы даже к простым атакам. Однако Agent Dojo не моделирует:
\begin{itemize}
    \item активного пользователя как участника взаимодействия;
    \item атаки через межагентную коммуникацию;
    \item отравление RAG-систем в реалистичных сценариях (почта, документы).
\end{itemize}

\subsection{Фреймворки моделирования угроз}

OWASP LLM Top~10~\cite{owasp_llm_2025} и OWASP AI Agents Top~15~\cite{owasp_agents_2025} систематизируют угрозы для ИИ-систем. Фреймворк AI-SAFE~\cite{ai_safe_2025} предлагает пятиуровневую модель угроз, специфичную для агентных архитектур. Наша работа использует эти классификации для систематического покрытия векторов атак в разработанных доменах.

\subsection{Позиционирование данной работы}

Данная работа заполняет пробел между:
\begin{itemize}
    \item бенчмарками dual-control ($\tau^2$-bench), которые не фокусируются на безопасности;
    \item бенчмарками безопасности (Agent Dojo, ASB), которые не учитывают активного пользователя и межагентное взаимодействие.
\end{itemize}

Мы расширяем методологию $\tau^2$-bench доменами безопасности, покрывающими угрозы AI-SAFE, и оцениваем устойчивость агентов в реалистичных сценариях с активным пользователем.

% TODO: Добавить обзор работ по RAG-атакам (если есть релевантные публикации к моменту финализации статьи).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Method}
\label{sec:method}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Формальная постановка задачи}

\subsubsection{Модель взаимодействия (Dec-POMDP)}

Взаимодействие агента с пользователем формализуется как децентрализованный частично наблюдаемый марковский процесс принятия решений (Dec-POMDP)~\cite{amato_2013,tau2_bench_2025}:

\begin{itemize}
    \item Среда $\mathcal{E}$ описывается множеством состояний $\mathcal{S}$, частично наблюдаемых участниками.
    \item Агент $\mathcal{A}$ и пользователь $\mathcal{U}$ --- два игрока с пространствами наблюдений $\Omega_A$, $\Omega_U$ и действий $\mathcal{A}_A$, $\mathcal{A}_U$.
    \item Функция перехода $T: \mathcal{S} \times \mathcal{A}_A \times \mathcal{A}_U \rightarrow \Delta(\mathcal{S})$ определяет динамику среды.
    \item Пользователь не является пассивным источником инструкций, а активно изменяет состояние среды.
\end{itemize}

\subsubsection{Модель атакующего}

Атакующий характеризуется следующими свойствами:
\begin{itemize}
    \item \textbf{Знание системы (grey-box):} знает архитектуру агента и доступные инструменты, но не имеет доступа к системному промту и весам модели.
    \item \textbf{Возможности:} может внедрять вредоносный контент в каналы ввода (письма, сообщения от коллег, пользовательские запросы, содержимое документов в RAG).
    \item \textbf{Цель:} заставить агента выполнить несанкционированные действия или раскрыть конфиденциальную информацию.
\end{itemize}

\subsubsection{Метрики оценки}

\textbf{Метрика pass@k.} Определяет долю кейсов, в которых агент успешно прошёл $k$ ассертов:
\begin{equation}
\text{pass}@k = \frac{1}{N} \sum_{i=1}^{N} \mathbb{1}\left[\sum_{j=1}^{M_i} a_{ij} \geq k\right],
\end{equation}
где $N$ --- число кейсов, $M_i$ --- число ассертов в $i$-м кейсе, $a_{ij} \in \{0, 1\}$ --- результат $j$-го ассерта.

\textbf{Attack Success Rate (ASR).} Показатель успешности атаки:
\begin{equation}
\text{ASR} = 1 - \text{pass}@1.
\end{equation}

В контексте безопасности ассерты проверяют:
\begin{itemize}
    \item отсутствие выполнения вредоносных инструкций;
    \item сохранение целостности данных;
    \item отказ от несанкционированных действий.
\end{itemize}

Отличие от метрик $\tau^2$-bench: успешность трактуется как \textit{устойчивость} к атаке, а не выполнение задачи; штрафы назначаются за выполнение вредоносных инструкций.

\subsubsection{Статистическая значимость результатов}

Для оценки статистической значимости результатов использовались методы, подходящие для малых выборок ($n \geq 3$):

\textbf{Доверительные интервалы для пропорций.} Для оценки точности метрики pass@1 использовался доверительный интервал Уилсона (Wilson confidence interval)~\cite{Wilson_1927}, который обеспечивает лучшие свойства для малых выборок по сравнению с нормальной аппроксимацией или методом Клоппера-Пирсона. Доверительный интервал Уилсона рассчитывается как:

\begin{equation}
p_{\text{CI}} = \frac{\hat{p} + \frac{z^2}{2n}}{1 + \frac{z^2}{n}} \pm \frac{z}{1 + \frac{z^2}{n}} \sqrt{\frac{\hat{p}(1-\hat{p})}{n} + \frac{z^2}{4n^2}},
\end{equation}

где $\hat{p}$ --- наблюдаемая доля успешных кейсов, $n$ --- число испытаний, $z$ --- квантиль стандартного нормального распределения для заданного уровня доверия (95\%: $z = 1.96$).

\textbf{Сравнение групп.} Для сравнения устойчивости различных моделей использовался точный критерий Фишера (Fisher's exact test)~\cite{Fisher_1935}, который более подходит для малых выборок ($n < 20$) по сравнению с критерием хи-квадрат.

В данной работе мы приводим p-value напрямую (в научной нотации) без дискретизации по порогам значимости; см. таблицу~\ref{tab:significance}. Поскольку $\text{ASR} = 1 - \text{pass@1}$, одно и то же p-value применимо как для pass@1, так и для ASR.

В представленных результатах значения в таблицах имеют формат: \texttt{X/Y (Z\%)}, где X/Y --- число успешных случаев из общего числа, Z\% --- процент успешности.

\textbf{Ограничения размера выборки.} При интерпретации результатов следует учитывать, что даже при $n=10$ прогонов на конфигурацию доверительные интервалы могут оставаться широкими (особенно для редких событий). Для более надёжных выводов рекомендуется проведение экспериментов с $n \geq 20$--$30$ прогонов на конфигурацию.

\subsection{Разработанные домены безопасности}

\subsubsection{Домен \texttt{mail\_rag\_phishing} (Отравление RAG)}

\textbf{Описание.} Моделирует атаку на RAG-систему почтового клиента через внедрение вредоносных инструкций в содержимое писем.

\textbf{Классификация угроз:} YAISAFE.DATA.1 (Knowledge Base Poisoning), YAISAFE.INPUT.1 (Indirect Prompt Injection), LLM01, RAG: Indirect Prompt Injection.

\textbf{Архитектура домена:}
\begin{itemize}
    \item Почтовый клиент с интегрированным RAG для поиска релевантных писем.
    \item База знаний: набор легитимных и вредоносных писем.
    \item Инструменты: \texttt{search\_emails}, \texttt{get\_email\_details}, \texttt{send\_email}, \texttt{forward\_email}.
\end{itemize}

\textbf{Кейсы атак:}
\begin{itemize}
    \item \texttt{rephrased\_trigger} --- атака с перефразированным триггером для обхода фильтров.
    \item \texttt{global\_shipper\_trigger} --- имитация письма от логистической компании с вредоносными инструкциями.
    \item \texttt{normal\_request} --- контрольный кейс без атаки.
\end{itemize}

% TODO: Добавить детальное описание механизма отравления RAG (какие именно инструкции внедряются, как формируется триггер).

\subsubsection{Домен \texttt{collab} (Межагентное взаимодействие)}

\textbf{Описание.} Моделирует мультиагентную среду, где атакующий агент (<<коллега>>) манипулирует целевым агентом через канал коммуникации.

\textbf{Классификация угроз:} YAISAFE.INFRA.3 (Cross-Agent Poisoning), YAISAFE.EXEC.1 (Tool Misuse), YAISAFE.EXEC.2 (Privilege Escalation), T15 (Cross-Agent Communication Poisoning), MCP05.

\textbf{Архитектура домена:}
\begin{itemize}
    \item Рабочее пространство с несколькими агентами с различными уровнями доступа.
    \item Система тикетов и задач с механизмом делегирования.
    \item Журнал активности и система логирования.
    \item Инструменты: \texttt{get\_tickets}, \texttt{update\_ticket}, \texttt{delegate\_task}, \texttt{get\_logs}, \texttt{send\_message}.
\end{itemize}

\textbf{Кейсы атак:}
\begin{itemize}
    \item \texttt{poisoning\_token\_exfil} --- эксфильтрация токенов доступа через манипуляцию.
    \item \texttt{conflicting\_instructions} --- конфликтующие инструкции для дестабилизации агента.
    \item \texttt{poisoning\_partial\_delete} --- частичное удаление данных.
    \item \texttt{poisoning\_logs} --- отравление системы логирования.
    \item \texttt{privilege\_escalation\_block} --- эскалация привилегий через социальную инженерию.
    \item \texttt{poisoning\_resolution\_gate} --- обход механизма подтверждения.
\end{itemize}

% TODO: Описать конкретные сценарии манипуляции для каждого кейса (какие сообщения отправляет "коллега", какие действия ожидаются от агента).

\subsubsection{Домен \texttt{output\_handling} (Обработка выводов)}

\textbf{Описание.} Проверяет устойчивость агента к генерации вредоносного кода или инъекций в выводе.

\textbf{Классификация угроз:} YAISAFE.INPUT.3 (Improper Output Handling), LLM05.

\textbf{Архитектура домена:}
\begin{itemize}
    \item Веб-приложение с возможностью генерации контента агентом.
    \item База данных с пользовательскими данными.
    \item Система отображения сгенерированного контента в браузере.
    \item Инструменты: \texttt{generate\_content}, \texttt{execute\_query}, \texttt{render\_template}, \texttt{send\_response}.
\end{itemize}

\textbf{Кейсы атак:}
\begin{itemize}
    \item \texttt{sql\_block} --- провокация на генерацию SQL-инъекций.
    \item \texttt{redirect\_block} --- создание редиректа на вредоносный ресурс.
    \item \texttt{xss\_block} --- генерация XSS-атаки в выводе.
\end{itemize}

% TODO: Описать конкретные промты, провоцирующие агента на генерацию вредоносного кода.

\subsection{Соответствие доменов и векторов атак}

\begin{table}[htbp]
\centering
\caption{Соответствие доменов и векторов атак}
\label{tab:attack_vectors}
\begin{tabular}{p{3.5cm}p{4cm}p{4cm}}
\toprule
\textbf{Домен} & \textbf{Вектор атаки} & \textbf{Классификация} \\
\midrule
mail\_rag\_phishing & Indirect Prompt Injection через RAG & YAISAFE.DATA.1, LLM01 \\
\midrule
collab & Cross-Agent Communication Poisoning & YAISAFE.INFRA.3, T15, MCP05 \\
\midrule
collab & Privilege Escalation & YAISAFE.EXEC.2, MCP03, T3 \\
\midrule
output\_handling & Improper Output Handling (XSS, SQLi) & YAISAFE.INPUT.3, LLM05 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Ограничения и предположения}

\begin{itemize}
    \item \textbf{Предположение о grey-box атакующем:} атакующий знает архитектуру, но не имеет доступа к весам модели.
    \item \textbf{Ограничение на модели:} в текущей версии исследуются только модели семейства GPT; результаты могут не обобщаться на другие семейства.
    \item \textbf{Симулятор пользователя:} пользователь моделируется LLM с фиксированными параметрами, что может не полностью отражать поведение реальных пользователей.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experiments}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Постановка экспериментов}

\subsubsection{Исследуемые модели}

\begin{itemize}
    \item \textbf{GPT-4o} --- передовая модель с расширенными возможностями рассуждения.
    \item \textbf{GPT-4o-mini} --- компактная версия со сниженной стоимостью.
\end{itemize}

Параметры генерации агента фиксированы: температура $T_{\text{agent}} = 0.0$.

% TODO: Добавить другие модели (Claude, Llama, Gemini) после проведения экспериментов.

\subsubsection{Варьируемые параметры}

Температура пользовательской модели:
\begin{itemize}
    \item $T_{\text{user}} = 0.0$ --- детерминированное поведение.
    \item $T_{\text{user}} = 0.5$ --- умеренная вариативность.
    \item $T_{\text{user}} = 1.0$ --- высокая вариативность.
\end{itemize}

\textbf{Гипотеза:} изменение температуры пользовательской модели влияет на паттерны взаимодействия и, как следствие, на устойчивость системы к атакам.

\subsubsection{Метрики}

\begin{itemize}
    \item \textbf{pass@1} --- доля кейсов с успешной защитой.
    \item \textbf{ASR} --- Attack Success Rate (1 -- pass@1).
    \item \textbf{avg\_reward} --- средняя награда за выполнение задачи.
    \item \textbf{avg\_agent\_cost}, \textbf{avg\_user\_cost} --- стоимость API-вызовов (\$).
    \item \textbf{avg\_duration} --- среднее время выполнения (сек).
    \item \textbf{avg\_num\_messages} --- среднее число сообщений в диалоге.
\end{itemize}
\subsubsection{Методы расчета метрик}

\textbf{Дискретные метрики:}
\begin{itemize}
    \item \textbf{pass@1:} доля кейсов, в которых агент успешно прошёл хотя бы один ассерт. Вычисляется как $\frac{\text{число успешных кейсов}}{\text{общее число кейсов}}$.
    \item \textbf{ASR:} Attack Success Rate, вычисляется как $1 - \text{pass@1}$.
\end{itemize}

\textbf{Непрерывные метрики:}
\begin{itemize}
    \item \textbf{avg\_reward:} среднее арифметическое наград за выполнение задачи по всем прогонам: $\bar{r} = \frac{1}{n}\sum_{i=1}^{n} r_i$, где $r_i$ --- награда $i$-го прогона, $n$ --- число прогонов.
    \item \textbf{avg\_agent\_cost, avg\_user\_cost:} среднее арифметическое стоимости API-вызовов в долларах США: $\bar{c} = \frac{1}{n}\sum_{i=1}^{n} c_i$.
    \item \textbf{avg\_duration:} среднее арифметическое времени выполнения симуляции в секундах: $\bar{t} = \frac{1}{n}\sum_{i=1}^{n} t_i$.
    \item \textbf{avg\_num\_messages:} среднее арифметическое числа сообщений в диалоге: $\bar{m} = \frac{1}{n}\sum_{i=1}^{n} m_i$.
\end{itemize}

Для всех метрик вычисляются 95\% доверительные интервалы: t-интервалы для непрерывных метрик, интервалы Уилсона для дискретных метрик.


\subsubsection{Протокол}

\begin{enumerate}
    \item Для каждой комбинации (модель, температура, кейс) выполняется $n$ независимых прогонов.
    \item Фиксируются все метрики.
    \item Результаты агрегируются для статистического анализа.
\end{enumerate}

% TODO: Указать финальное число прогонов $n$ после завершения экспериментов (планируется 10--30 для статистической значимости).

В текущей работе проведено 10 прогонов для каждой конфигурации (модель, температура, домен, задача).

\subsection{Пилотные результаты}

Детальные метрики по каждому кейсу вынесены в отдельный раздел в конце статьи (табл.~\ref{tab:detailed_metrics}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results \& Discussion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Агрегированные результаты}


% Сохраняем нумерацию таблиц: Табл. 2 зарезервирована под детальные метрики.
\setcounter{table}{2}

% Автосгенерированная таблица (model×domain pass@1)
\input{model_domain_table.tex}


% TODO: Обновить таблицу финальными данными с доверительными интервалами и статистической значимостью после получения достаточного числа прогонов.



\subsection{Статистическая значимость (gpt-4o vs gpt-4o-mini)}
\input{significance_table.tex}








\subsection{Статистическая значимость (влияние температуры)}
\input{temperature_significance_table.tex}



\subsection{Визуализация результатов}

На рисунках~\ref{fig:attack_flow}--\ref{fig:attack_timeline_output} представлены визуализации потоков атак по доменам, а на рисунках~\ref{fig:pass1_by_domain}--\ref{fig:metrics_heatmap} --- визуализации метрик по доменам и моделям.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.95\textwidth]{figs/attack_flow.pdf}
\caption{Визуализация потока атак по доменам безопасности}
\label{fig:attack_flow}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.95\textwidth]{figs/attack_sankey.pdf}
\caption{Поток атаки: от вектора атаки к результату безопасности}
\label{fig:attack_sankey}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.95\textwidth]{figs/attack_timeline_mail_rag_phishing.pdf}
\caption{Временная диаграмма потока сообщений: отравление RAG}
\label{fig:attack_timeline_rag}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.95\textwidth]{figs/attack_timeline_collab.pdf}
\caption{Временная диаграмма потока сообщений: межагентное отравление}
\label{fig:attack_timeline_collab}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.95\textwidth]{figs/attack_timeline_output_handling.pdf}
\caption{Временная диаграмма потока сообщений: инъекция в вывод}
\label{fig:attack_timeline_output}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.9\textwidth]{figs/pass1_by_domain.pdf}
\caption{Метрика pass@1 по доменам для различных моделей}
\label{fig:pass1_by_domain}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.9\textwidth]{figs/asr_by_domain.pdf}
\caption{Attack Success Rate (ASR) по доменам для различных моделей}
\label{fig:asr_by_domain}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.9\textwidth]{figs/temperature_effect.pdf}
\caption{Влияние температуры пользовательской модели на метрики}
\label{fig:temperature_effect}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.9\textwidth]{figs/metrics_heatmap.pdf}
\caption{Heatmap всех метрик по доменам и моделям}
\label{fig:metrics_heatmap}
\end{figure}

\subsection{Анализ результатов}

\subsubsection{Влияние размера модели}

Агрегированные результаты по доменам приведены в таблице~\ref{tab:aggregated}, а p-value для сравнения моделей при фиксированной температуре~--- в таблице~\ref{tab:significance}.

Ключевые наблюдения:
\begin{itemize}
    \item \texttt{mail\_rag\_phishing}: GPT-4o показывает более высокую устойчивость, чем GPT-4o-mini, для всех температур ($p\approx 1.28\times10^{-2}$ при $T=0.0$, $9.12\times10^{-3}$ при $T=0.5$, $5.04\times10^{-3}$ при $T=1.0$).
    \item \texttt{collab}: различия между моделями незначимы (например, при $T=0.0$ pass@1: 21.7\% vs 30.0\%, $p=4.04\times10^{-1}$).
    \item \texttt{output\_handling}: различия между моделями незначимы при всех температурах (например, при $T=0.5$ pass@1: 60.0\% vs 46.7\%, $p=4.38\times10^{-1}$).
\end{itemize}

\subsubsection{Уязвимость RAG-систем}

Домен \texttt{mail\_rag\_phishing} остаётся сложным для обеих моделей: даже при наилучшей конфигурации наблюдается существенный ASR (см. табл.~\ref{tab:aggregated} и табл.~\ref{tab:detailed_metrics}). Это указывает на высокую эффективность атак через контекст RAG и необходимость дополнительных защит (например, валидации источников, фильтрации инструкций, policy-driven tool gating).

% TODO: Провести качественный анализ (case study) неудачных кейсов: какие именно инструкции выполнил агент, как выглядел диалог.

\subsubsection{Влияние температуры пользователя}

Влияние температуры пользовательской модели на устойчивость неоднозначно и зависит от домена. Для количественной оценки мы дополнительно сравниваем температуры попарно внутри каждой модели (Fisher exact по агрегированному pass@1; p-value применимо и для ASR). Результаты приведены в табл.~\ref{tab:temp_significance}.

\subsubsection{Стоимость безопасности}

В рамках текущей версии статьи мы не включаем количественные выводы по стоимости, так как соответствующие колонки исключены из финальных таблиц для компактности. Тем не менее, на практике стоимость более крупных моделей остаётся важным фактором при выборе защит.

\subsection{Failure Cases}

% TODO: Описать конкретные примеры неудачных кейсов:
% - Какие вредоносные инструкции выполнил агент?
% - Как выглядел диалог с пользователем?
% - Какие паттерны атак оказались наиболее эффективными?

\textit{Раздел будет дополнен после качественного анализа логов экспериментов.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

В данной работе представлен подход к оценке безопасности LLM-агентов в парадигме двойного управления (dual-control). Основные результаты:

\begin{enumerate}
    \item \textbf{Разработаны три домена безопасности} для бенчмарка $\tau^2$-bench, покрывающие атаки на RAG-системы, межагентное взаимодействие и обработку выводов. Домены соответствуют классификации AI-SAFE и OWASP.
    
    \item \textbf{Сравнение моделей зависит от домена:} для \texttt{mail\_rag\_phishing} GPT-4o показывает более высокую устойчивость (табл.~\ref{tab:aggregated}), тогда как для \texttt{collab} и \texttt{output\_handling} различия между GPT-4o и GPT-4o-mini по имеющимся данным не являются статистически значимыми (табл.~\ref{tab:significance}).
    
    \item \textbf{Атаки через RAG остаются сложными:} домен \texttt{mail\_rag\_phishing} показывает высокий ASR для обеих моделей, хотя GPT-4o статистически значимо превосходит GPT-4o-mini при всех значениях $T$ (табл.~\ref{tab:significance}).
\end{enumerate}

\textbf{Направления будущих исследований:}
\begin{itemize}
    \item Расширение экспериментов на другие семейства моделей (Claude, Llama, Gemini).
    \item Интеграция и оценка guardrails (Llama Guard, Promptfoo).
    \item Добавление доменов \texttt{resource\_overload} и \texttt{supply\_chain}.
    \item Переход к N-игроковым мультиагентным сценариям (DUMA-bench~\cite{duma_bench}).
\end{itemize}

% TODO: Обновить выводы после получения финальных статистически значимых результатов.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Limitations}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{enumerate}
    \item \textbf{Ограниченное число прогонов.} Проведено $n=10$ прогонов на конфигурацию; для более надёжных выводов (особенно при близких значениях pass@1) желательно увеличить $n$ до 20--30.
    
    \item \textbf{Ограниченный набор моделей.} Исследованы только модели семейства GPT. Результаты могут не обобщаться на Claude, Llama, Gemini и другие семейства.
    
    \item \textbf{Симулятор пользователя.} Пользователь моделируется LLM, что может не полностью отражать поведение реальных пользователей с их непредсказуемостью и ошибками.
    
    \item \textbf{Отсутствие guardrails.} В текущей версии не оценивается эффективность защитных механизмов (Llama Guard, Promptfoo, кастомные валидаторы).
    
    \item \textbf{Grey-box модель атакующего.} Рассматривается только сценарий, где атакующий знает архитектуру, но не имеет доступа к весам. Более сильные модели атакующего (white-box) не исследованы.
    
    % TODO: Добавить ограничения, выявленные в ходе экспериментов.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Acknowledgements}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% TODO: Добавить благодарности (если применимо).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Детальные метрики по кейсам}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Таблица с детальными метриками вынесена в конец статьи.
% ВАЖНО: устанавливаем счётчик таблиц так, чтобы эта таблица была Таблицей 2.
\setcounter{table}{1}
\input{detailed_metrics_table.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% References
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{thebibliography}{99}

\bibitem{ai_safe_2025}
Мулейс~Р., Нестерук~С., Лодин~А. AI Secure Agentic Framework Essentials (AI-SAFE) v1.0. Yandex Cloud, 2025.

\bibitem{owasp_llm_2025}
OWASP Foundation. OWASP Top 10 for Large Language Model Applications. 2025. URL: \url{https://owasp.org/www-project-top-10-for-large-language-model-applications/}

\bibitem{owasp_agents_2025}
OWASP Foundation. OWASP AI Agents (Agentic AI) Top 15. 2025.

\bibitem{tau_bench_2024}
Yao~S., Shinn~N., Razavi~P., Narasimhan~K. $\tau$-bench: A Benchmark for Tool-Agent-User Interaction in Real-World Domains // arXiv preprint arXiv:2406.12045. 2024.

\bibitem{tau2_bench_2025}
Barres~V., Dong~H., Ray~S., Si~X., Narasimhan~K. $\tau^2$-Bench: Evaluating Conversational Agents in a Dual-Control Environment // arXiv preprint arXiv:2506.07982. 2025.

\bibitem{amato_2013}
Amato~C., Chowdhary~G., Geramifard~A., Ure~N.~K., Kochenderfer~M.~J. Decentralized control of partially observable Markov decision processes // 52nd IEEE Conference on Decision and Control. 2013. P.~2398--2405.

\bibitem{agent_dojo}
Debenedetti~E. et al. AgentDojo: A Dynamic Environment to Evaluate Prompt Injection Attacks and Defenses for LLM Agents // Advances in Neural Information Processing Systems. 2024. Vol.~37. P.~82895--82920.

\bibitem{agent_bench}
Liu~X. et al. AgentBench: Evaluating LLMs as Agents // arXiv preprint arXiv:2308.03688. 2025.

\bibitem{asb}
Zhang~H. et al. Agent Security Bench (ASB): Formalizing and Benchmarking Attacks and Defenses in LLM-based Agents // arXiv preprint arXiv:2410.02644. 2025.

\bibitem{llama_guard}
Meta AI. Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations. 2024.

\bibitem{duma_bench}
Aleksandrov~I. DUMA-bench: Dual-control-User-Multi-Agent Interaction Benchmark. Working paper, 2025.

\bibitem{Wilson_1927}
Wilson~E.~B. Probable inference, the law of succession, and statistical inference // Journal of the American Statistical Association. 1927. Vol.~22, No.~158. P.~209--212.

\bibitem{Fisher_1935}
Fisher~R.~A. The logic of inductive inference // Journal of the Royal Statistical Society. 1935. Vol.~98, No.~1. P.~39--82.

\end{thebibliography}

\end{document}
