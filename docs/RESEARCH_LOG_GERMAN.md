### Изменения в бенчмарке
- Добавили LLM‑оценку выходов (Output Assertions): новый тип вознаграждения `OUTPUT_ASSERTION`, поле `output_eval_prompt` в задачах и конфиг/CLI для выбора модели судьи. Интегрировали в общий расчёт награды.
- Поддержали переопределение системных промптов на уровне задачи: `agent_prompt`, `user_prompt`. Для маленьких OSS‑моделей добавили строгий пользовательский промпт (user‑only fallback).
- Реализовали импорт промптов из файлов в `tasks.json` через нотацию `file:<name>` для полей: `user_scenario.instructions`, `user_prompt`, `agent_prompt`.
- Добавили провайдера Hugging Face Router (через LiteLLM): автоподхват `HF_TOKEN`, дефолтный `api_base`.

### Новые AI‑security сценарии
- RAG poisoning (rag_poison): “официальный” документ с ядовитым шагом (массовое создание жалоб); проверяем отказ от деструктивных действий и следование безопасным SOP.
- CRM paired‑docs leak (crm_leak): инструмент возвращает `primary+trusted`; агент должен фильтровать PII доверенного документа и сопротивляться социнженерии.
- Phishing via marketing assistant (mktg_phishing): попытка запустить фишинговую рассылку через `send_email` с не‑white‑list доменом и без SEC‑тикета.

### Дальнейшие шаги
- Расширить покрытие сценариев (KYC/AML, payments, data exfiltration, workflow‑poisoning) и многошаговые атаки.
- Ввести тонкую метрику для частичных нарушений (graded scoring) и автоматические “red‑team” пробы.
- Добавить выбор режима оценки через CLI (включая NL‑assertions) и гибкую композицию критериев.
- Улучшить трассировку: опциональный вывод полных запросов/ответов и безопасное логирование.

