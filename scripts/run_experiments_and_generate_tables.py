#!/usr/bin/env python3
"""
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤, –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–∞–±–ª–∏—Ü/–≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π.

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –≤—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª:
1. –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
2. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è LaTeX —Ç–∞–±–ª–∏—Ü
4. –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π
5. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ template.tex
6. –ö–æ–º–ø–∏–ª—è—Ü–∏—è PDF (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
"""

import json
import os
import re
import shutil
import subprocess
import sys
import threading
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns

try:
    from tqdm import tqdm

    HAS_TQDM = True
except ImportError:
    HAS_TQDM = False

# Add project root and src to path to import tau2 (must be before importing result_collection)
project_root = Path(__file__).parent.parent
src_dir = project_root / "src"
if str(src_dir) not in sys.path:
    sys.path.insert(0, str(src_dir))
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# Add scripts directory to path
scripts_dir = Path(__file__).parent
if str(scripts_dir) not in sys.path:
    sys.path.insert(0, str(scripts_dir))

from result_collection import (
    load_simulations,
    load_simulation_file,
    compute_task_metrics,
)
from generate_statistical_tables import (
    generate_detailed_metrics_table_latex,
    generate_aggregated_table_latex,
    generate_model_domain_table_latex,
    generate_significance_table_latex,
    generate_temperature_significance_table_latex,
)


def _model_id_for_results(model: str | None) -> str:
    """Normalize provider-prefixed model names for filenames/reporting."""
    if not isinstance(model, str):
        return str(model)
    if model.startswith("openrouter/"):
        return model.split("/")[-1]
    if model.startswith("openai/"):
        return model.split("/", 1)[1]
    return model


def _sanitize_model_for_filename(model: str) -> str:
    return re.sub(r"[^A-Za-z0-9_.-]+", "-", model).strip("-")


def _normalize_model_name(model: str | None) -> str:
    return _model_id_for_results(model)


def run_single_experiment(
    cmd: List[str], output_file: Path, exp_name: str, idx: int, total: int
) -> Tuple[bool, float, Optional[str]]:
    """
    –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–¥–∏–Ω —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç.

    Returns:
        Tuple of (success, duration, error_message)
    """
    exp_start_time = time.time()

    try:
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            bufsize=1,
            cwd=Path.cwd(),
        )

        # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        stdout, stderr = process.communicate()
        returncode = process.returncode

        exp_duration = time.time() - exp_start_time

        if returncode != 0:
            error_msg = (
                stderr[:500]
                if stderr
                else stdout[:500]
                if stdout
                else "No error message"
            )
            return (False, exp_duration, error_msg)
        else:
            return (True, exp_duration, None)

    except Exception as e:
        exp_duration = time.time() - exp_start_time
        return (False, exp_duration, str(e))


def run_all_experiments(
    models: List[str],
    temperatures: List[float],
    domains: Dict[str, List[str]],
    num_trials: int = 10,
    max_concurrency: int = 3,
    output_dir: Optional[Path] = None,  # –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –æ—Å—Ç–∞–≤–ª–µ–Ω–æ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    parallel_experiments: int = 4,  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
    force_rerun: bool = False,  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –≤—Å–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã
) -> Path:
    """
    –ó–∞–ø—É—Å—Ç–∏—Ç—å –≤—Å–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã.

    Args:
        models: –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π ['gpt-4o', 'gpt-4o-mini', 'gpt-5.1', 'gpt-5.2']
        temperatures: –°–ø–∏—Å–æ–∫ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä [0.0, 0.5, 1.0]
        domains: –°–ª–æ–≤–∞—Ä—å {domain: [task_ids]}
        num_trials: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≥–æ–Ω–æ–≤ –Ω–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        max_concurrency: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—É—Å–∫–æ–≤
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

    Returns:
        Path to results directory
    """
    # tau2 —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ñ–∞–π–ª—ã –≤ data/tau2/simulations/ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
    # --save-to –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –∏–º—è —Ñ–∞–π–ª–∞ –ë–ï–ó —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
    from tau2.utils.utils import DATA_DIR

    actual_output_dir = DATA_DIR / "simulations"
    actual_output_dir.mkdir(parents=True, exist_ok=True)

    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤—Å–µ—Ö –∑–∞–¥–∞—á –¥–æ–º–µ–Ω–∞ –∏–∑ tasks.json
    def get_all_tasks_for_domain(domain_name: str) -> List[str]:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –≤—Å–µ –∑–∞–¥–∞—á–∏ –¥–æ–º–µ–Ω–∞ –∏–∑ tasks.json."""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø—É—Ç–µ–π (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å –ø–µ—Ä–≤—ã–º)
        possible_paths = [
            DATA_DIR
            / "tau2"
            / "domains"
            / domain_name
            / "tasks.json",  # –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å
            DATA_DIR / "domains" / domain_name / "tasks.json",
            Path("data/tau2/domains") / domain_name / "tasks.json",
            Path(__file__).parent.parent
            / "data"
            / "tau2"
            / "domains"
            / domain_name
            / "tasks.json",
        ]

        tasks_file = None
        for path in possible_paths:
            if path.exists():
                tasks_file = path
                break

        if not tasks_file:
            print(f"Warning: tasks.json not found for domain {domain_name}")
            print(f"  Checked paths: {[str(p) for p in possible_paths]}")
            return []

        try:
            with open(tasks_file, "r", encoding="utf-8") as f:
                tasks_data = json.load(f)
                task_ids = [task["id"] for task in tasks_data if "id" in task]
                print(f"  Found {len(task_ids)} tasks in {tasks_file}")
                return task_ids
        except Exception as e:
            print(
                f"Warning: Could not load tasks for {domain_name} from {tasks_file}: {e}"
            )
            import traceback

            traceback.print_exc()
            return []

    # –ö—ç—à –¥–ª—è –∑–∞–¥–∞—á –¥–æ–º–µ–Ω–æ–≤, —á—Ç–æ–±—ã –Ω–µ –∑–∞–≥—Ä—É–∂–∞—Ç—å –∏—Ö –º–Ω–æ–≥–æ–∫—Ä–∞—Ç–Ω–æ
    domain_tasks_cache = {}

    commands = []
    for model in models:
        for temp in temperatures:
            for domain, tasks in domains.items():
                # –ï—Å–ª–∏ –∑–∞–¥–∞—á–∏ –Ω–µ —É–∫–∞–∑–∞–Ω—ã, –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤—Å–µ –∑–∞–¥–∞—á–∏ –¥–æ–º–µ–Ω–∞ (—Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º)
                if not tasks:
                    if domain not in domain_tasks_cache:
                        domain_tasks_cache[domain] = get_all_tasks_for_domain(domain)
                    tasks = domain_tasks_cache[domain]
                    if not tasks:
                        print(f"Warning: No tasks found for domain {domain}, skipping")
                        continue
                    if model == models[0] and temp == temperatures[0]:
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–µ—Ä–≤–æ–π –∑–∞–≥—Ä—É–∑–∫–µ
                        print(f"Loaded {len(tasks)} tasks for domain {domain}")

                for task in tasks:
                    # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è (tau2 –¥–æ–±–∞–≤–∏—Ç .json –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
                    model_id = _model_id_for_results(model)
                    file_name = f"paper_results_{domain}_{_sanitize_model_for_filename(model_id)}_T{temp}_{task}"
                    # –§–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                    output_file = actual_output_dir / f"{file_name}.json"

                    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–º–∞–Ω–¥—É —Ç–æ—á–Ω–æ –∫–∞–∫ –≤ README
                    cmd = [
                        "tau2",
                        "run",
                        "--domain",
                        domain,
                        "--agent-llm",
                        model,
                        "--user-llm",
                        model,
                        "--user-llm-args",
                        json.dumps({"temperature": temp}),
                        "--num-trials",
                        str(num_trials),
                        "--task-ids",
                        task,
                        "--save-to",
                        file_name,  # –ë–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –∏ –ø—É—Ç–∏
                        "--max-concurrency",
                        str(max_concurrency),
                    ]
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞: —É–±–µ–¥–∏–º—Å—è, —á—Ç–æ –≤—Å–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã - —Å—Ç—Ä–æ–∫–∏
                    cmd = [str(arg) for arg in cmd]
                    commands.append((cmd, output_file))

    print(f"Total configurations to run: {len(commands)}")

    # –ó–∞–ø—É—Å—Ç–∏—Ç—å –∫–æ–º–∞–Ω–¥—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º
    completed = 0
    skipped = 0
    errors = 0
    start_time = time.time()
    times = []  # –î–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Å—Ä–µ–¥–Ω–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏

    # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å tqdm –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω, –∏–Ω–∞—á–µ –ø—Ä–æ—Å—Ç–æ–π –≤—ã–≤–æ–¥
    # –î–ª—è thread-safe —Ä–∞–±–æ—Ç—ã —Å tqdm –∏—Å–ø–æ–ª—å–∑—É–µ–º lock
    from threading import Lock

    pbar_lock = Lock()

    if HAS_TQDM:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –Ω–∞ –º–µ—Å—Ç–µ
        # mininterval –∏ miniters –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è —á–∞—Å—Ç–æ—Ç—ã –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π
        pbar = tqdm(
            total=len(commands),
            desc="Running experiments",
            unit="exp",
            file=sys.stderr,
            ncols=120,
            leave=True,
            mininterval=1.0,
            miniters=1,
            bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]",
        )
    else:
        pbar = None

    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –æ–¥–Ω–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
    def run_single_experiment(idx_cmd_file):
        idx, cmd, output_file = idx_cmd_file
        exp_start_time = time.time()
        thread_id = threading.current_thread().ident
        cmd_str = " ".join(cmd)  # –î–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

        # –ï—Å–ª–∏ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
        if output_file.exists() and not force_rerun:
            with pbar_lock:
                if HAS_TQDM:
                    pbar.update(1)
            return (True, 0, "skipped", output_file.name)

        # –ï—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫, —É–¥–∞–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª
        if output_file.exists() and force_rerun:
            output_file.unlink()

        # –ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–∏–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç
        model = cmd[cmd.index("--agent-llm") + 1] if "--agent-llm" in cmd else "unknown"
        domain = cmd[cmd.index("--domain") + 1] if "--domain" in cmd else "unknown"
        task = cmd[cmd.index("--task-ids") + 1] if "--task-ids" in cmd else "unknown"
        short_name = f"{domain[:15]}/{model[:10]}/{task.split('_')[-1][:20]}"

        # –ó–∞–ø—É—Å—Ç–∏—Ç—å –∫–æ–º–∞–Ω–¥—É
        try:
            # –õ–æ–≥–∏—Ä—É–µ–º –Ω–∞—á–∞–ª–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ—Å—Ç–∏
            start_msg = f"[Thread-{thread_id % 10000}] [{idx}] üöÄ START: {short_name}"
            print(start_msg, flush=True)

            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                bufsize=1,
                cwd=Path.cwd(),
            )

            # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è (—ç—Ç–æ –±–ª–æ–∫–∏—Ä—É–µ—Ç, –Ω–æ –≤ —Ä–∞–∑–Ω—ã—Ö –ø–æ—Ç–æ–∫–∞—Ö –ø—Ä–æ—Ü–µ—Å—Å—ã –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)
            stdout, stderr = process.communicate()
            returncode = process.returncode

            end_msg = f"[Thread-{thread_id % 10000}] [{idx}] ‚úÖ DONE: {short_name} ({time.time() - exp_start_time:.1f}s)"
            print(end_msg, flush=True)

            exp_duration = time.time() - exp_start_time

            if returncode != 0:
                # –°–æ–±–∏—Ä–∞–µ–º –ø–æ–ª–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
                error_parts = []
                if stderr:
                    error_parts.append(f"STDERR: {stderr}")
                if stdout:
                    error_parts.append(f"STDOUT: {stdout}")
                if not error_parts:
                    error_parts.append("No error message")
                error_msg = "\n".join(error_parts)
                # –î–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ—Ä–æ—Ç–∫—É—é –≤–µ—Ä—Å–∏—é
                error_msg_short = (
                    stderr[:500]
                    if stderr
                    else stdout[:500]
                    if stdout
                    else "No error message"
                )
                with pbar_lock:
                    if HAS_TQDM:
                        pbar.update(1)
                return (False, exp_duration, error_msg, short_name)
            else:
                with pbar_lock:
                    if HAS_TQDM:
                        pbar.update(1)
                return (True, exp_duration, None, short_name)

        except Exception as e:
            exp_duration = time.time() - exp_start_time
            with pbar_lock:
                if HAS_TQDM:
                    pbar.update(1)
            return (False, exp_duration, str(e), short_name)

    # –ó–∞–ø—É—Å—Ç–∏—Ç—å –∫–æ–º–∞–Ω–¥—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º max_concurrency –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ—Å—Ç–∏
    # –ü—Ä–æ–≤–µ—Ä–∏–º, —á—Ç–æ tau2 –¥–æ—Å—Ç—É–ø–µ–Ω (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ)
    if commands:
        tau2_path = shutil.which("tau2")
        if not tau2_path:
            raise FileNotFoundError(
                "tau2 command not found in PATH. "
                "Make sure tau2 is installed: pip install -e ."
            )

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    indexed_commands = [
        (idx, cmd, output_file) for idx, (cmd, output_file) in enumerate(commands, 1)
    ]

    print(f"üöÄ Starting parallel execution with max_workers={max_concurrency}")
    print(f"   Total experiments: {len(indexed_commands)}")

    # –û—á–∏—Å—Ç–∏—Ç—å –ª–æ–≥ –æ—à–∏–±–æ–∫ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å)
    project_root = Path(__file__).parent.parent
    error_log_file = project_root / "experiment_errors.log"
    if error_log_file.exists():
        error_log_file.unlink()

    with ThreadPoolExecutor(max_workers=max_concurrency) as executor:
        # –û—Ç–ø—Ä–∞–≤–∏—Ç—å –≤—Å–µ –∑–∞–¥–∞—á–∏ —Å—Ä–∞–∑—É - –æ–Ω–∏ –±—É–¥—É—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        future_to_item = {
            executor.submit(run_single_experiment, item): item
            for item in indexed_commands
        }

        print(f"‚úÖ All {len(future_to_item)} tasks submitted to thread pool")
        print(f"   Executing up to {max_concurrency} experiments in parallel...\n")

        # –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –º–µ—Ä–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        for future in as_completed(future_to_item):
            item = future_to_item[future]
            idx = item[0]
            try:
                success, duration, error_msg, name = future.result()
                if duration > 0:  # –ù–µ —Å—á–∏—Ç–∞–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ
                    times.append(duration)

                if success:
                    if error_msg == "skipped":
                        skipped += 1
                    else:
                        completed += 1
                else:
                    errors += 1
                    # –í—Å–µ–≥–¥–∞ –ª–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
                    print(f"\n   ‚ùå ERROR [{idx}] after {duration:.1f}s: {name}")
                    if error_msg:
                        error_preview = (
                            error_msg[:500] if len(error_msg) > 500 else error_msg
                        )
                        print(f"   Error: {error_preview}")
                        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–æ–ª–Ω—É—é –æ—à–∏–±–∫—É –≤ —Ñ–∞–π–ª –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å)
                        project_root = Path(__file__).parent.parent
                        error_log_file = project_root / "experiment_errors.log"
                        try:
                            # –ü–æ–ª—É—á–∏—Ç—å –∫–æ–º–∞–Ω–¥—É –∏–∑ item
                            item_cmd = item[1] if len(item) > 1 else None
                            cmd_str = (
                                " ".join(item_cmd) if item_cmd else "unknown command"
                            )
                            with open(error_log_file, "a", encoding="utf-8") as f:
                                f.write(f"\n{'=' * 80}\n")
                                f.write(f"Experiment [{idx}]: {name}\n")
                                f.write(f"Command: {cmd_str}\n")
                                f.write(f"Duration: {duration:.1f}s\n")
                                f.write(f"Full error message:\n{error_msg}\n")
                                f.write(f"{'=' * 80}\n")
                        except Exception as log_err:
                            print(f"   ‚ö†Ô∏è  Failed to write to error log: {log_err}")
            except Exception as e:
                errors += 1
                project_root = Path(__file__).parent.parent
                error_log_file = project_root / "experiment_errors.log"
                print(f"\n   ‚ùå Exception in experiment {idx}: {e}")
                try:
                    with open(error_log_file, "a", encoding="utf-8") as f:
                        f.write(f"\n{'=' * 80}\n")
                        f.write(
                            f"Exception in experiment [{idx}]: {item[3] if len(item) > 3 else 'unknown'}\n"
                        )
                        f.write(f"Exception type: {type(e).__name__}\n")
                        f.write(f"Exception message: {str(e)}\n")
                        import traceback

                        f.write(f"Traceback:\n{traceback.format_exc()}\n")
                        f.write(f"{'=' * 80}\n")
                except Exception as log_err:
                    print(f"   ‚ö†Ô∏è  Failed to write exception to error log: {log_err}")

    if HAS_TQDM:
        pbar.close()

    total_time = time.time() - start_time
    total_time_str = str(timedelta(seconds=int(total_time)))

    print(f"\n{'=' * 80}")
    print(f"üìä Summary:")
    print(f"   ‚úÖ Completed: {completed}")
    print(f"   ‚è≠Ô∏è  Skipped: {skipped}")
    print(f"   ‚ùå Errors: {errors}")
    print(f"   ‚è±Ô∏è  Total time: {total_time_str}")
    if completed > 0 and times:
        avg_time = np.mean(times)
        print(f"   üìà Average time per experiment: {avg_time:.1f}s")
    print(f"{'=' * 80}\n")

    # –ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ª–æ–≥–µ –æ—à–∏–±–æ–∫
    project_root = Path(__file__).parent.parent
    error_log_file = project_root / "experiment_errors.log"
    if error_log_file.exists() and errors > 0:
        print(
            f"‚ö†Ô∏è  {errors} errors occurred. Full error details saved to: {error_log_file}"
        )
        print(f"   To view errors: cat {error_log_file}\n")

    return actual_output_dir


def process_all_results(
    results_dir: Path, result_files: Optional[List[Path]] = None
) -> Dict:
    """
    –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –≤—ã—á–∏—Å–ª–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏.

    Args:
        results_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏

    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –¥–ª—è –≤—Å–µ—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π
    """
    if result_files is None:
        result_files = list(results_dir.glob("paper_results_*.json"))

    if not result_files:
        raise ValueError(f"No result files found in {results_dir}")

    print(f"Loading {len(result_files)} result files...")

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª –æ—Ç–¥–µ–ª—å–Ω–æ, —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∏ –º–æ–≥—É—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ä–∞–∑–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    all_metrics = {}

    for file_path in result_files:
        try:
            # –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–º–µ–Ω—ã –∏–∑ —ç—Ç–æ–≥–æ —Ñ–∞–π–ª–∞
            file_domains = load_simulation_file(file_path)

            for domain, results in file_domains.items():
                # –ò–∑–≤–ª–µ—á—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
                model = _normalize_model_name(results.info.agent_info.llm)
                user_model = _normalize_model_name(results.info.user_info.llm)
                # –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –±–µ—Ä–µ—Ç—Å—è –∏–∑ user_info.llm_args (–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è –º–æ–¥–µ–ª—å)
                temp = (
                    results.info.user_info.llm_args.get("temperature", 0.0)
                    if results.info.user_info.llm_args
                    else 0.0
                )

                # –ü–æ–ª—É—á–∏—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–∞–¥–∞—á–∏ –¥–ª—è —ç—Ç–æ–≥–æ –¥–æ–º–µ–Ω–∞
                task_ids = set(sim.task_id for sim in results.simulations)

                print(
                    f"   Processing {domain}: {len(task_ids)} tasks, {len(results.simulations)} simulations"
                )

                for task_id in task_ids:
                    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–∏–º—É–ª—è—Ü–∏–∏ –¥–ª—è —ç—Ç–æ–π –∑–∞–¥–∞—á–∏
                    task_sims = [
                        sim for sim in results.simulations if sim.task_id == task_id
                    ]
                    if not task_sims:
                        print(f"      Warning: No simulations found for task {task_id}")
                        continue

                    metrics = compute_task_metrics(results, task_id)
                    if metrics:
                        key = f"{domain}_{model}_T{temp}_{task_id}"
                        all_metrics[key] = {
                            "domain": domain,
                            "model": model,
                            "user_model": user_model,
                            "temperature": temp,
                            "task": task_id,
                            **metrics,
                        }
                        print(
                            f"      ‚úÖ Computed metrics for {task_id}: pass@1={metrics.get('pass^1', 'N/A'):.2f}, ASR={metrics.get('ASR', 'N/A'):.2f}"
                        )
                    else:
                        print(f"      ‚ö†Ô∏è  No metrics computed for {task_id}")
        except Exception as e:
            print(f"Warning: Failed to process {file_path}: {e}")
            continue

    print(f"Computed metrics for {len(all_metrics)} configurations")

    if len(all_metrics) == 0:
        print("‚ö†Ô∏è  WARNING: No metrics computed!")
        print("   This might mean:")
        print("   - Files are empty or corrupted")
        print("   - Simulations don't have the expected structure")
        print("   - Task IDs don't match")
        # –ü–æ–ø—Ä–æ–±—É–µ–º –ø–æ–∫–∞–∑–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        if result_files:
            try:
                from tau2.data_model.simulation import Results

                sample = Results.load(result_files[0])
                print(f"\n   Sample file structure:")
                print(f"   - Domain: {sample.info.environment_info.domain_name}")
                print(f"   - Agent LLM: {sample.info.agent_info.llm}")
                print(f"   - User LLM: {sample.info.user_info.llm}")
                print(f"   - Number of simulations: {len(sample.simulations)}")
                if sample.simulations:
                    print(
                        f"   - First simulation task_id: {sample.simulations[0].task_id}"
                    )
                    print(
                        f"   - All task_ids: {set(s.task_id for s in sample.simulations)}"
                    )
            except Exception as debug_e:
                print(f"   Could not inspect file structure: {debug_e}")

    return all_metrics


def generate_visualizations(metrics: Dict, output_dir: Path):
    """
    –°–æ–∑–¥–∞—Ç—å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è LaTeX.

    Args:
        metrics: –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
    """
    output_dir.mkdir(parents=True, exist_ok=True)

    if not metrics:
        print("‚ö†Ô∏è  No metrics to visualize - creating placeholder files")
        # –°–æ–∑–¥–∞—Ç—å –ø—É—Å—Ç—ã–µ –∑–∞–≥–ª—É—à–∫–∏ –¥–ª—è LaTeX
        for fig_name in [
            "pass1_by_domain",
            "asr_by_domain",
            "temperature_effect",
            "metrics_heatmap",
        ]:
            placeholder_path = output_dir / f"{fig_name}.pdf"
            # –°–æ–∑–¥–∞—Ç—å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π PDF –∑–∞–≥–ª—É—à–∫—É
            try:
                fig, ax = plt.subplots(figsize=(8, 6))
                ax.text(
                    0.5,
                    0.5,
                    f"Placeholder: {fig_name}\n\nNo data available\n\nRun experiments to generate visualizations",
                    ha="center",
                    va="center",
                    fontsize=12,
                    wrap=True,
                )
                ax.set_xticks([])
                ax.set_yticks([])
                ax.spines["top"].set_visible(False)
                ax.spines["right"].set_visible(False)
                ax.spines["bottom"].set_visible(False)
                ax.spines["left"].set_visible(False)
                plt.savefig(placeholder_path, dpi=150, bbox_inches="tight")
                plt.close()
                print(f"   Created placeholder: {placeholder_path}")
            except Exception as e:
                print(f"   Could not create placeholder {fig_name}: {e}")
        return

    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ DataFrame –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
    df = pd.DataFrame(list(metrics.values()))

    if df.empty or len(metrics) == 0:
        print("‚ö†Ô∏è  No metrics to visualize - creating placeholder files")
        # –°–æ–∑–¥–∞—Ç—å –ø—É—Å—Ç—ã–µ –∑–∞–≥–ª—É—à–∫–∏ –¥–ª—è LaTeX, —á—Ç–æ–±—ã –∫–æ–º–ø–∏–ª—è—Ü–∏—è –Ω–µ –ø–∞–¥–∞–ª–∞
        for fig_name in [
            "pass1_by_domain",
            "asr_by_domain",
            "temperature_effect",
            "metrics_heatmap",
        ]:
            placeholder_path = output_dir / f"{fig_name}.pdf"
            try:
                fig, ax = plt.subplots(figsize=(8, 6))
                ax.text(
                    0.5,
                    0.5,
                    f"Placeholder: {fig_name}\n\nNo data available yet.\nRun experiments to generate visualizations.",
                    ha="center",
                    va="center",
                    fontsize=12,
                    wrap=True,
                )
                ax.set_xticks([])
                ax.set_yticks([])
                ax.spines["top"].set_visible(False)
                ax.spines["right"].set_visible(False)
                ax.spines["bottom"].set_visible(False)
                ax.spines["left"].set_visible(False)
                plt.savefig(placeholder_path, dpi=150, bbox_inches="tight")
                plt.close()
                print(f"   Created placeholder: {placeholder_path.name}")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Could not create placeholder {fig_name}: {e}")
        return

    # –ù–∞—É—á–Ω—ã–π —Å—Ç–∏–ª—å –¥–ª—è –∂—É—Ä–Ω–∞–ª–æ–≤
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∏–ª—å —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ –¥–µ–∫–æ—Ä–∞—Ü–∏—è–º–∏ –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–º–∏ —à—Ä–∏—Ñ—Ç–∞–º–∏
    plt.rcParams.update(
        {
            "font.family": "serif",
            "font.serif": ["Computer Modern Roman", "Times New Roman", "DejaVu Serif"],
            "font.size": 10,
            "axes.labelsize": 11,
            "axes.titlesize": 12,
            "xtick.labelsize": 10,
            "ytick.labelsize": 10,
            "legend.fontsize": 9,
            "figure.titlesize": 12,
            "text.usetex": False,  # –û—Ç–∫–ª—é—á–∞–µ–º LaTeX –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            "axes.linewidth": 0.8,
            "grid.linewidth": 0.5,
            "lines.linewidth": 1.5,
            "patch.linewidth": 0.5,
            "xtick.major.width": 0.8,
            "ytick.major.width": 0.8,
            "xtick.minor.width": 0.6,
            "ytick.minor.width": 0.6,
            "axes.spines.top": False,
            "axes.spines.right": False,
        }
    )

    # –¶–≤–µ—Ç–æ–≤–∞—è –ø–∞–ª–∏—Ç—Ä–∞ –¥–ª—è –Ω–∞—É—á–Ω—ã—Ö –ø—É–±–ª–∏–∫–∞—Ü–∏–π (colorblind-friendly)
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞–ª–∏—Ç—Ä—É, –∫–æ—Ç–æ—Ä–∞—è —Ö–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ —á–µ—Ä–Ω–æ-–±–µ–ª–æ–º –∏ —Ü–≤–µ—Ç–Ω–æ–º –≤–∏–¥–µ
    colors = ["#1f77b4", "#ff7f0e", "#2ca02c", "#d62728", "#9467bd", "#8c564b"]
    sns.set_palette(colors)

    # 1. –ì—Ä–∞—Ñ–∏–∫ pass@1 –ø–æ –¥–æ–º–µ–Ω–∞–º –∏ –º–æ–¥–µ–ª—è–º
    fig, ax = plt.subplots(figsize=(6, 4))
    if "domain" in df.columns and "model" in df.columns:
        if "success_count" in df.columns and "num_trials" in df.columns:
            pass1_agg = (
                df.groupby(["model", "domain"], as_index=False)
                .agg({"success_count": "sum", "num_trials": "sum"})
                .copy()
            )
            pass1_agg["pass^1"] = pass1_agg["success_count"] / pass1_agg["num_trials"]
        elif "pass^1" in df.columns:
            pass1_agg = (
                df.groupby(["model", "domain"], as_index=False)
                .agg({"pass^1": "mean"})
                .copy()
            )
        else:
            pass1_agg = None

        if pass1_agg is not None:
            pivot_pass1 = pass1_agg.pivot_table(
                values="pass^1", index="model", columns="domain", aggfunc="mean"
            )
            pivot_pass1.plot(
                kind="bar", ax=ax, width=0.7, edgecolor="black", linewidth=0.5
            )
            ax.set_ylabel("pass@1", fontsize=11)
            ax.set_xlabel("–ú–æ–¥–µ–ª—å", fontsize=11)
            ax.legend(
                title="–î–æ–º–µ–Ω",
                fontsize=9,
                frameon=True,
                fancybox=False,
                edgecolor="black",
            )
            ax.grid(True, alpha=0.2, axis="y", linestyle="--", linewidth=0.5)
            ax.set_ylim([0, 1.05])
            plt.xticks(rotation=45, ha="right")
            plt.tight_layout()
            plt.savefig(
                output_dir / "pass1_by_domain.pdf",
                dpi=300,
                bbox_inches="tight",
                pad_inches=0.1,
            )
            plt.close()
            print(f"Saved: {output_dir / 'pass1_by_domain.pdf'}")

    # 2. –ì—Ä–∞—Ñ–∏–∫ ASR –ø–æ –¥–æ–º–µ–Ω–∞–º –∏ –º–æ–¥–µ–ª—è–º
    fig, ax = plt.subplots(figsize=(6, 4))
    if "domain" in df.columns and "model" in df.columns:
        if "success_count" in df.columns and "num_trials" in df.columns:
            asr_agg = (
                df.groupby(["model", "domain"], as_index=False)
                .agg({"success_count": "sum", "num_trials": "sum"})
                .copy()
            )
            asr_agg["ASR"] = 1.0 - (asr_agg["success_count"] / asr_agg["num_trials"])
        elif "ASR" in df.columns:
            asr_agg = (
                df.groupby(["model", "domain"], as_index=False)
                .agg({"ASR": "mean"})
                .copy()
            )
        else:
            asr_agg = None

        if asr_agg is not None:
            pivot_asr = asr_agg.pivot_table(
                values="ASR", index="model", columns="domain", aggfunc="mean"
            )
            pivot_asr.plot(
                kind="bar", ax=ax, width=0.7, edgecolor="black", linewidth=0.5
            )
            ax.set_ylabel("ASR", fontsize=11)
            ax.set_xlabel("–ú–æ–¥–µ–ª—å", fontsize=11)
            ax.legend(
                title="–î–æ–º–µ–Ω",
                fontsize=9,
                frameon=True,
                fancybox=False,
                edgecolor="black",
            )
            ax.grid(True, alpha=0.2, axis="y", linestyle="--", linewidth=0.5)
            ax.set_ylim([0, 1.05])
            plt.xticks(rotation=45, ha="right")
            plt.tight_layout()
            plt.savefig(
                output_dir / "asr_by_domain.pdf",
                dpi=300,
                bbox_inches="tight",
                pad_inches=0.1,
            )
            plt.close()
            print(f"Saved: {output_dir / 'asr_by_domain.pdf'}")

    # 3. –ì—Ä–∞—Ñ–∏–∫ –≤–ª–∏—è–Ω–∏—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã
    # –í–ê–ñ–ù–û: –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º–æ—Å—Ç–∏ —Å —Ç–∞–±–ª–∏—Ü–∞–º–∏/heatmap –∞–≥—Ä–µ–≥–∏—Ä—É–µ–º –ø–æ (model, temperature, domain).
    if "temperature" in df.columns and "domain" in df.columns and "model" in df.columns:
        group_cols = ["model", "temperature", "domain"]

        if "success_count" in df.columns and "num_trials" in df.columns:
            discrete_agg = (
                df.groupby(group_cols, as_index=False)
                .agg({"success_count": "sum", "num_trials": "sum"})
                .copy()
            )
            discrete_agg["pass^1"] = (
                discrete_agg["success_count"] / discrete_agg["num_trials"]
            )
            discrete_agg["ASR"] = 1.0 - discrete_agg["pass^1"]
        else:
            base_metrics = [m for m in ["pass^1", "ASR"] if m in df.columns]
            if not base_metrics:
                discrete_agg = df[group_cols].drop_duplicates().copy()
            else:
                discrete_agg = (
                    df.groupby(group_cols, as_index=False)
                    .agg({m: "mean" for m in base_metrics})
                    .copy()
                )

        continuous_metrics = [
            m
            for m in [
                "avg_reward",
                "avg_agent_cost",
                "avg_duration",
                "avg_num_messages",
            ]
            if m in df.columns
        ]
        if continuous_metrics:
            cont_agg = (
                df.groupby(group_cols, as_index=False)
                .agg({m: "mean" for m in continuous_metrics})
                .copy()
            )
            temp_df = discrete_agg.merge(cont_agg, on=group_cols, how="left")
        else:
            temp_df = discrete_agg

        fig, axes = plt.subplots(2, 3, figsize=(12, 8))
        metric_names = [
            "pass^1",
            "ASR",
            "avg_reward",
            "avg_agent_cost",
            "avg_duration",
            "avg_num_messages",
        ]
        metric_labels = {
            "pass^1": "pass@1",
            "ASR": "ASR",
            "avg_reward": "–°—Ä–µ–¥–Ω—è—è –Ω–∞–≥—Ä–∞–¥–∞",
            "avg_agent_cost": "–°—Ç–æ–∏–º–æ—Å—Ç—å –∞–≥–µ–Ω—Ç–∞ ($)",
            "avg_duration": "–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (—Å)",
            "avg_num_messages": "–ß–∏—Å–ª–æ —Å–æ–æ–±—â–µ–Ω–∏–π",
        }

        models = sorted(temp_df["model"].unique())
        linestyles = ["-", "--", ":", "-."]
        markers = ["o", "s", "^", "D"]
        model_style = {
            model: {
                "linestyle": linestyles[idx % len(linestyles)],
                "marker": markers[idx % len(markers)],
            }
            for idx, model in enumerate(models)
        }

        domains = sorted(temp_df["domain"].unique())

        for idx, metric in enumerate(metric_names):
            if metric not in temp_df.columns:
                continue

            ax = axes[idx // 3, idx % 3]
            for domain_idx, domain in enumerate(domains):
                domain_color = colors[domain_idx % len(colors)]
                for model in models:
                    subset = temp_df[
                        (temp_df["domain"] == domain) & (temp_df["model"] == model)
                    ]
                    if subset.empty:
                        continue

                    subset_sorted = subset.sort_values("temperature")
                    ax.plot(
                        subset_sorted["temperature"],
                        subset_sorted[metric],
                        label=f"{domain} ({model})",
                        color=domain_color,
                        linestyle=model_style[model]["linestyle"],
                        marker=model_style[model]["marker"],
                        linewidth=1.5,
                        markersize=5,
                        markerfacecolor=domain_color,
                        markeredgecolor="black",
                        markeredgewidth=0.5,
                    )

            ax.set_xlabel("–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞", fontsize=10)
            ax.set_ylabel(metric_labels.get(metric, metric), fontsize=10)
            ax.legend(
                fontsize=7, frameon=True, fancybox=False, edgecolor="black", ncol=2
            )
            ax.grid(True, alpha=0.2, linestyle="--", linewidth=0.5)

        plt.tight_layout()
        plt.savefig(
            output_dir / "temperature_effect.pdf",
            dpi=300,
            bbox_inches="tight",
            pad_inches=0.1,
        )
        plt.close()
        print(f"Saved: {output_dir / 'temperature_effect.pdf'}")

    # 4. Heatmap –º–µ—Ç—Ä–∏–∫–∏ pass@1 –ø–æ –¥–æ–º–µ–Ω–∞–º –∏ (–º–æ–¥–µ–ª—å, —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞)
    # –í–ê–ñ–ù–û: –¥–µ–ª–∞–µ–º —Ç–æ—Ç –∂–µ —Ç–∏–ø –∞–≥—Ä–µ–≥–∞—Ü–∏–∏, —á—Ç–æ –∏ –≤ —Ç–∞–±–ª–∏—Ü–∞—Ö: —Å—É–º–º–∏—Ä—É–µ–º successes/trials
    # –ø–æ –≤—Å–µ–º –∫–µ–π—Å–∞–º –¥–æ–º–µ–Ω–∞ –¥–ª—è –∫–∞–∂–¥–æ–π –ø–∞—Ä—ã (model, temperature).
    if (
        "success_count" in df.columns
        and "num_trials" in df.columns
        and "temperature" in df.columns
        and "domain" in df.columns
        and "model" in df.columns
    ):
        from matplotlib import colors as mcolors

        agg = (
            df.groupby(["model", "temperature", "domain"], as_index=False)
            .agg({"success_count": "sum", "num_trials": "sum"})
            .copy()
        )
        agg["pass@1"] = agg["success_count"] / agg["num_trials"]

        # Make readable row labels
        agg["model_T"] = agg.apply(
            lambda r: f"{r['model']} (T={float(r['temperature']):g})", axis=1
        )

        fig, ax = plt.subplots(figsize=(8, 6))
        heatmap_data = agg.pivot_table(
            values="pass@1", index="model_T", columns="domain", aggfunc="mean"
        )

        # Stable ordering: sort by model then temperature.
        heatmap_data = heatmap_data.reindex(
            sorted(
                heatmap_data.index,
                key=lambda s: (s.split(" (T=")[0], float(s.split("T=")[1].rstrip(")"))),
            )
        )

        cmap = "cividis"
        norm = mcolors.PowerNorm(gamma=0.6, vmin=0.0, vmax=1.0)

        sns.heatmap(
            heatmap_data,
            annot=True,
            fmt=".2f",
            cmap=cmap,
            norm=norm,
            ax=ax,
            cbar_kws={"label": "pass@1", "shrink": 0.85},
            linewidths=0.5,
            linecolor="white",
            square=False,
            annot_kws={"fontsize": 8},
        )
        ax.set_xlabel("–î–æ–º–µ–Ω", fontsize=11)
        ax.set_ylabel("–ú–æ–¥–µ–ª—å (T)", fontsize=11)
        ax.tick_params(labelsize=9)
        ax.set_xticklabels(ax.get_xticklabels(), rotation=30, ha="right")
        ax.set_yticklabels(ax.get_yticklabels(), rotation=0)
        plt.tight_layout()
        plt.savefig(
            output_dir / "metrics_heatmap.pdf",
            dpi=300,
            bbox_inches="tight",
            pad_inches=0.1,
        )
        plt.close()
        print(f"Saved: {output_dir / 'metrics_heatmap.pdf'}")

    print(f"\nAll visualizations saved to {output_dir}")


def update_template_tex(
    template_path: Path,
    detailed_table_path: Path,
    model_domain_table_path: Path,
    significance_table_path: Path,
    temp_significance_table_path: Path,
    visualizations_dir: Path,
):
    """
    –û–±–Ω–æ–≤–∏—Ç—å template.tex —Å –Ω–æ–≤—ã–º–∏ —Ç–∞–±–ª–∏—Ü–∞–º–∏ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è–º–∏.
    """
    template_content = template_path.read_text()

    # 1. –î–æ–±–∞–≤–∏—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫ –≤ —Ä–∞–∑–¥–µ–ª 4.1.3 (–ø–æ—Å–ª–µ —Å–ø–∏—Å–∫–∞ –º–µ—Ç—Ä–∏–∫)
    metrics_description = """
\\subsubsection{–ú–µ—Ç–æ–¥—ã —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫}

\\textbf{–î–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏:}
\\begin{itemize}
    \\item \\textbf{pass@1:} –¥–æ–ª—è –∫–µ–π—Å–æ–≤, –≤ –∫–æ—Ç–æ—Ä—ã—Ö –∞–≥–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ—à—ë–ª —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –∞—Å—Å–µ—Ä—Ç. –í—ã—á–∏—Å–ª—è–µ—Ç—Å—è –∫–∞–∫ $\\frac{\\text{—á–∏—Å–ª–æ —É—Å–ø–µ—à–Ω—ã—Ö –∫–µ–π—Å–æ–≤}}{\\text{–æ–±—â–µ–µ —á–∏—Å–ª–æ –∫–µ–π—Å–æ–≤}}$.
    \\item \\textbf{ASR:} Attack Success Rate, –≤—ã—á–∏—Å–ª—è–µ—Ç—Å—è –∫–∞–∫ $1 - \\text{pass@1}$.
\\end{itemize}

\\textbf{–ù–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏:}
\\begin{itemize}
    \\item \\textbf{avg\\_reward:} —Å—Ä–µ–¥–Ω–µ–µ –∞—Ä–∏—Ñ–º–µ—Ç–∏—á–µ—Å–∫–æ–µ –Ω–∞–≥—Ä–∞–¥ –∑–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏ –ø–æ –≤—Å–µ–º –ø—Ä–æ–≥–æ–Ω–∞–º: $\\bar{r} = \\frac{1}{n}\\sum_{i=1}^{n} r_i$, –≥–¥–µ $r_i$ --- –Ω–∞–≥—Ä–∞–¥–∞ $i$-–≥–æ –ø—Ä–æ–≥–æ–Ω–∞, $n$ --- —á–∏—Å–ª–æ –ø—Ä–æ–≥–æ–Ω–æ–≤.
    \\item \\textbf{avg\\_duration:} —Å—Ä–µ–¥–Ω–µ–µ –∞—Ä–∏—Ñ–º–µ—Ç–∏—á–µ—Å–∫–æ–µ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å–∏–º—É–ª—è—Ü–∏–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö: $\\bar{t} = \\frac{1}{n}\\sum_{i=1}^{n} t_i$.
    \\item \\textbf{avg\\_num\\_messages:} —Å—Ä–µ–¥–Ω–µ–µ –∞—Ä–∏—Ñ–º–µ—Ç–∏—á–µ—Å–∫–æ–µ —á–∏—Å–ª–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –¥–∏–∞–ª–æ–≥–µ: $\\bar{m} = \\frac{1}{n}\\sum_{i=1}^{n} m_i$.
\\end{itemize}

–î–ª—è –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫ –≤—ã—á–∏—Å–ª—è—é—Ç—Å—è 95\\% –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã: t-–∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –¥–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫, –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –£–∏–ª—Å–æ–Ω–∞ –¥–ª—è –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫.
"""

    # –ù–∞–π—Ç–∏ –º–µ—Å—Ç–æ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏ (–ø–æ—Å–ª–µ —Å–ø–∏—Å–∫–∞ –º–µ—Ç—Ä–∏–∫)
    metrics_list_marker = (
        "\\item \\textbf{avg\\_num\\_messages} --- —Å—Ä–µ–¥–Ω–µ–µ —á–∏—Å–ª–æ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –¥–∏–∞–ª–æ–≥–µ."
    )
    if (
        metrics_list_marker in template_content
        and "–ú–µ—Ç–æ–¥—ã —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫" not in template_content
    ):
        # –í—Å—Ç–∞–≤–∏—Ç—å –ø–æ—Å–ª–µ —Å–ø–∏—Å–∫–∞ –º–µ—Ç—Ä–∏–∫, –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º –ø–æ–¥—Ä–∞–∑–¥–µ–ª–æ–º
        insert_pos = template_content.find(metrics_list_marker) + len(
            metrics_list_marker
        )
        # –ù–∞–π—Ç–∏ –∫–æ–Ω–µ—Ü —Å–ø–∏—Å–∫–∞
        end_list = template_content.find("\\end{itemize}", insert_pos)
        if end_list != -1:
            template_content = (
                template_content[: end_list + len("\\end{itemize}")]
                + metrics_description
                + template_content[end_list + len("\\end{itemize}") :]
            )

    import re

    # 2) –ó–∞–º–µ–Ω–∏—Ç—å –ø–∏–ª–æ—Ç–Ω—É—é —Ç–∞–±–ª–∏—Ü—É tab:results –Ω–∞ –∞–≤—Ç–æ—Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é
    if detailed_table_path.exists():
        detailed_rel = detailed_table_path.relative_to(template_path.parent)
        detailed_section = (
            "\n% –ê–≤—Ç–æ—Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ (–¥–µ—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏)\n"
            f"\\input{{{detailed_rel}}}\n"
        )

        template_content = template_content.replace(
            "–í —Ç–∞–±–ª–∏—Ü–µ~\\ref{tab:results} –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –ø–æ –≤—Å–µ–º –¥–æ–º–µ–Ω–∞–º.",
            "–í —Ç–∞–±–ª–∏—Ü–µ~\\ref{tab:detailed_metrics} –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –ø–æ –≤—Å–µ–º –¥–æ–º–µ–Ω–∞–º.",
        )

        tab_results_pattern = (
            r"\\begin\{longtable\}.*?\\label\{tab:results\}.*?\\end\{longtable\}"
        )
        template_content, n_subs = re.subn(
            tab_results_pattern,
            lambda _m: detailed_section,
            template_content,
            flags=re.DOTALL,
        )

        if n_subs == 0:
            print(
                "Warning: could not find tab:results longtable; "
                "skipping detailed table insertion"
            )

    # 3) –û–±–Ω–æ–≤–∏—Ç—å –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É –≤ Results & Discussion
    if model_domain_table_path.exists():
        model_domain_rel = model_domain_table_path.relative_to(template_path.parent)
        model_domain_section = (
            "\n% –ê–≤—Ç–æ—Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ (model√ódomain pass@1)\n"
            f"\\input{{{model_domain_rel}}}\n"
        )

        # Replace only inside the Results & Discussion aggregated subsection
        agg_subsection_start = "\\subsection{–ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã}"
        viz_subsection_start = "\\subsection{–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤}"
        if (
            agg_subsection_start in template_content
            and viz_subsection_start in template_content
        ):
            start_idx = template_content.find(agg_subsection_start)
            end_idx = template_content.find(viz_subsection_start, start_idx)
            subsection = template_content[start_idx:end_idx]

            table_pattern = r"\\begin\{table\}\[htbp\].*?\\end\{table\}"
            subsection, n_subs = re.subn(
                table_pattern,
                lambda _m: model_domain_section,
                subsection,
                flags=re.DOTALL,
            )

            if n_subs > 0:
                template_content = (
                    template_content[:start_idx]
                    + subsection
                    + template_content[end_idx:]
                )

    # 4) –í—Å—Ç–∞–≤–∏—Ç—å —Ç–∞–±–ª–∏—Ü—ã —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ (–º–æ–¥–µ–ª–∏ –∏ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã)
    viz_marker = "\\subsection{–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤}"

    if (
        significance_table_path.exists()
        and "significance_table.tex" not in template_content
    ):
        sig_rel = significance_table_path.relative_to(template_path.parent)
        sig_section = (
            "\n\\subsection{–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å (gpt-4o vs gpt-4o-mini)}\n"
            f"\\input{{{sig_rel}}}\n"
        )
        if viz_marker in template_content:
            template_content = template_content.replace(
                viz_marker, sig_section + "\n" + viz_marker
            )

    if (
        temp_significance_table_path.exists()
        and "temperature_significance_table.tex" not in template_content
    ):
        temp_rel = temp_significance_table_path.relative_to(template_path.parent)
        temp_section = (
            "\n\\subsection{–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å (–≤–ª–∏—è–Ω–∏–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã)}\n"
            f"\\input{{{temp_rel}}}\n"
        )
        if viz_marker in template_content:
            template_content = template_content.replace(
                viz_marker, temp_section + "\n" + viz_marker
            )

    # 4. –û–±–Ω–æ–≤–∏—Ç—å —Ä–∞–∑–¥–µ–ª —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è–º–∏ (–Ω–µ —É–¥–∞–ª—è—Ç—å attack-–ø–ª–æ—Ç—ã)
    visualizations_section = f"""
\\subsection{{–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤}}

–ù–∞ —Ä–∏—Å—É–Ω–∫–∞—Ö~\\ref{{fig:attack_flow}}--\\ref{{fig:attack_timeline_output}} –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–æ—Ç–æ–∫–æ–≤ –∞—Ç–∞–∫ –ø–æ –¥–æ–º–µ–Ω–∞–º, –∞ –Ω–∞ —Ä–∏—Å—É–Ω–∫–∞—Ö~\\ref{{fig:pass1_by_domain}}--\\ref{{fig:metrics_heatmap}} --- –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –º–µ—Ç—Ä–∏–∫ –ø–æ –¥–æ–º–µ–Ω–∞–º –∏ –º–æ–¥–µ–ª—è–º.

\\begin{{figure}}[htbp]
\\centering
\\includegraphics[width=0.95\\textwidth]{{figs/attack_flow.pdf}}
\\caption{{–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ—Ç–æ–∫–∞ –∞—Ç–∞–∫ –ø–æ –¥–æ–º–µ–Ω–∞–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏}}
\\label{{fig:attack_flow}}
\\end{{figure}}

\\begin{{figure}}[htbp]
\\centering
\\includegraphics[width=0.95\\textwidth]{{figs/attack_sankey.pdf}}
\\caption{{–ü–æ—Ç–æ–∫ –∞—Ç–∞–∫–∏: –æ—Ç –≤–µ–∫—Ç–æ—Ä–∞ –∞—Ç–∞–∫–∏ –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏}}
\\label{{fig:attack_sankey}}
\\end{{figure}}

\\begin{{figure}}[htbp]
\\centering
\\includegraphics[width=0.95\\textwidth]{{figs/attack_timeline_mail_rag_phishing.pdf}}
\\caption{{–í—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞ –ø–æ—Ç–æ–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π: –æ—Ç—Ä–∞–≤–ª–µ–Ω–∏–µ RAG}}
\\label{{fig:attack_timeline_rag}}
\\end{{figure}}

\\begin{{figure}}[htbp]
\\centering
\\includegraphics[width=0.95\\textwidth]{{figs/attack_timeline_collab.pdf}}
\\caption{{–í—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞ –ø–æ—Ç–æ–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π: –º–µ–∂–∞–≥–µ–Ω—Ç–Ω–æ–µ –æ—Ç—Ä–∞–≤–ª–µ–Ω–∏–µ}}
\\label{{fig:attack_timeline_collab}}
\\end{{figure}}

\\begin{{figure}}[htbp]
\\centering
\\includegraphics[width=0.95\\textwidth]{{figs/attack_timeline_output_handling.pdf}}
\\caption{{–í—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞ –ø–æ—Ç–æ–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π: –∏–Ω—ä–µ–∫—Ü–∏—è –≤ –≤—ã–≤–æ–¥}}
\\label{{fig:attack_timeline_output}}
\\end{{figure}}

\\begin{{figure}}[htbp]
\\centering
\\includegraphics[width=0.9\\textwidth]{{figs/pass1_by_domain.pdf}}
\\caption{{–ú–µ—Ç—Ä–∏–∫–∞ pass@1 –ø–æ –¥–æ–º–µ–Ω–∞–º –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π}}
\\label{{fig:pass1_by_domain}}
\\end{{figure}}

\\begin{{figure}}[htbp]
\\centering
\\includegraphics[width=0.9\\textwidth]{{figs/asr_by_domain.pdf}}
\\caption{{Attack Success Rate (ASR) –ø–æ –¥–æ–º–µ–Ω–∞–º –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π}}
\\label{{fig:asr_by_domain}}
\\end{{figure}}

\\begin{{figure}}[htbp]
\\centering
\\includegraphics[width=0.9\\textwidth]{{figs/temperature_effect.pdf}}
\\caption{{–í–ª–∏—è–Ω–∏–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –º–µ—Ç—Ä–∏–∫–∏}}
\\label{{fig:temperature_effect}}
\\end{{figure}}

\\begin{{figure}}[htbp]
\\centering
\\includegraphics[width=0.9\\textwidth]{{figs/metrics_heatmap.pdf}}
\\caption{{Heatmap –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫ –ø–æ –¥–æ–º–µ–Ω–∞–º –∏ –º–æ–¥–µ–ª—è–º}}
\\label{{fig:metrics_heatmap}}
\\end{{figure}}
"""

    analysis_marker = "\\subsection{–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤}"
    viz_marker = "\\subsection{–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤}"

    if viz_marker in template_content and analysis_marker in template_content:
        start_idx = template_content.find(viz_marker)
        end_idx = template_content.find(analysis_marker, start_idx)
        if end_idx != -1:
            template_content = (
                template_content[:start_idx]
                + visualizations_section
                + "\n"
                + template_content[end_idx:]
            )
    elif analysis_marker in template_content:
        template_content = template_content.replace(
            analysis_marker, visualizations_section + "\n" + analysis_marker
        )

    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    template_path.write_text(template_content)
    print(f"Updated {template_path}")


def compile_pdf(template_path: Path) -> bool:
    """–°–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞—Ç—å PDF –∏–∑ LaTeX."""
    template_dir = template_path.parent
    original_dir = os.getcwd()

    try:
        os.chdir(template_dir)

        cmd = [
            "pdflatex",
            "-interaction=nonstopmode",
            "-halt-on-error",
            template_path.name,
        ]

        # –ü–µ—Ä–≤–∞—è –∫–æ–º–ø–∏–ª—è—Ü–∏—è - –∏—Å–ø–æ–ª—å–∑—É–µ–º errors='replace' –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–µ-UTF8 —Å–∏–º–≤–æ–ª–æ–≤
        result = subprocess.run(cmd, capture_output=True, text=True, errors="replace")
        if result.returncode != 0:
            print(f"Error compiling LaTeX (first pass):")
            if result.stderr:
                print(result.stderr[:1000])  # –ü–µ—Ä–≤—ã–µ 1000 —Å–∏–º–≤–æ–ª–æ–≤ –æ—à–∏–±–∫–∏
            if result.stdout:
                # –ü–æ–∫–∞–∑–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏ –≤—ã–≤–æ–¥–∞ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
                lines = result.stdout.split("\n")
                error_lines = [l for l in lines if "error" in l.lower() or "!" in l]
                if error_lines:
                    print("\nLaTeX errors found:")
                    for line in error_lines[-10:]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 –æ—à–∏–±–æ–∫
                        print(f"  {line}")
            return False

        # –í—Ç–æ—Ä–∞—è –∫–æ–º–ø–∏–ª—è—Ü–∏—è –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Å—ã–ª–æ–∫
        result2 = subprocess.run(cmd, capture_output=True, text=True, errors="replace")
        if result2.returncode != 0:
            print(
                f"Warning: Second compilation had errors (this is often OK for references)"
            )

        # –ü–æ—Å–ª–µ os.chdir(template_dir) –Ω—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å
        pdf_path = Path("template.pdf")
        if pdf_path.exists():
            # –ü–æ–ª–Ω—ã–π –ø—É—Ç—å –¥–ª—è –≤—ã–≤–æ–¥–∞
            full_pdf_path = template_dir / "template.pdf"
            print(f"‚úÖ PDF compiled: {full_pdf_path}")
            return True
        else:
            print("‚ùå PDF file not found after compilation")
            # –ü–æ–ø—Ä–æ–±—É–µ–º –ø–æ–∫–∞–∑–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
            print(f"Files in {template_dir}:")
            for f in sorted(template_dir.glob("*.pdf"))[:5]:
                print(f"  - {f.name}")
            return False

    finally:
        os.chdir(original_dir)


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –≤—Å–µ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞."""
    import argparse

    parser = argparse.ArgumentParser(
        description="–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤, –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–∞–±–ª–∏—Ü/–≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π"
    )
    parser.add_argument(
        "--models",
        nargs="+",
        default=["gpt-4o", "gpt-4o-mini", "gpt-5.1", "gpt-5.2"],
        help="–ú–æ–¥–µ–ª–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è",
    )
    parser.add_argument(
        "--temperatures",
        nargs="+",
        type=float,
        default=[0.0, 0.5, 1.0],
        help="–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π –º–æ–¥–µ–ª–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 0.0, 0.5, 1.0)",
    )
    parser.add_argument(
        "--domains",
        nargs="+",
        default=["mail_rag_phishing", "collab", "output_handling"],
        help="–î–æ–º–µ–Ω—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è",
    )
    parser.add_argument(
        "--num-trials", type=int, default=10, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≥–æ–Ω–æ–≤ –Ω–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é"
    )
    parser.add_argument(
        "--max-concurrency",
        type=int,
        default=3,
        help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—É—Å–∫–æ–≤",
    )
    parser.add_argument(
        "--skip-experiments",
        action="store_true",
        help="–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –∑–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ (—Ç–æ–ª—å–∫–æ –æ–±—Ä–∞–±–æ—Ç–∫–∞)",
    )
    parser.add_argument(
        "--allow-incomplete",
        action="store_true",
        help="–†–∞–∑—Ä–µ—à–∏—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Ç–∞–±–ª–∏—Ü/–≥—Ä–∞—Ñ–∏–∫–æ–≤ –ø—Ä–∏ –Ω–µ–ø–æ–ª–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å–∫—Ä–∏–ø—Ç –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è)",
    )
    parser.add_argument(
        "--force-rerun",
        action="store_true",
        help="–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –≤—Å–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã (—É–¥–∞–ª–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã)",
    )
    parser.add_argument(
        "--skip-visualizations",
        action="store_true",
        help="–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π",
    )
    parser.add_argument(
        "--compile-pdf",
        action="store_true",
        default=True,
        help="–°–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞—Ç—å PDF –ø–æ—Å–ª–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: True)",
    )
    parser.add_argument(
        "--results-dir",
        type=Path,
        default=None,
        help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é data/tau2/simulations/)",
    )
    parser.add_argument(
        "--template-path",
        type=Path,
        default=Path("docs/paper_template/template.tex"),
        help="–ü—É—Ç—å –∫ template.tex",
    )

    args = parser.parse_args()

    # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∑–∞–¥–∞—á–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–æ–º–µ–Ω–∞
    # –ï—Å–ª–∏ —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á –ø—É—Å—Ç–æ–π, —Å–∫—Ä–∏–ø—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∑–∏—Ç –≤—Å–µ –∑–∞–¥–∞—á–∏ –∏–∑ tasks.json
    tasks_by_domain = {
        "mail_rag_phishing": [],  # –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ = –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤—Å–µ –∑–∞–¥–∞—á–∏
        "collab": [],  # –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ = –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤—Å–µ –∑–∞–¥–∞—á–∏
        "output_handling": [],  # –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ = –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤—Å–µ –∑–∞–¥–∞—á–∏
    }

    # –ï—Å–ª–∏ –¥–æ–º–µ–Ω –Ω–µ —É–∫–∞–∑–∞–Ω –≤ tasks_by_domain, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ (–∑–∞–≥—Ä—É–∑–∏—Ç –≤—Å–µ –∑–∞–¥–∞—á–∏)
    domains_dict = {d: tasks_by_domain.get(d, []) for d in args.domains}

    # –®–∞–≥ 1: –ó–∞–ø—É—Å—Ç–∏—Ç—å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã
    if not args.skip_experiments:
        print("=" * 80)
        print("–®–ê–ì 1: –ó–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤")
        print("=" * 80)
        run_all_experiments(
            args.models,
            args.temperatures,
            domains_dict,
            args.num_trials,
            args.max_concurrency,
            args.results_dir,
            force_rerun=args.force_rerun,
        )
    else:
        print("–ü—Ä–æ–ø—É—Å–∫ –∑–∞–ø—É—Å–∫–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ (--skip-experiments)")

    # –®–∞–≥ 2: –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\n" + "=" * 80)
    print("–®–ê–ì 2: –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    print("=" * 80)
    # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    if args.results_dir is None:
        from tau2.utils.utils import DATA_DIR

        results_dir = DATA_DIR / "simulations"
    else:
        results_dir = args.results_dir

    # –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –æ–∂–∏–¥–∞–µ–º—ã–π —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö
    # –¥–æ–º–µ–Ω–æ–≤/–º–æ–¥–µ–ª–µ–π/—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä, —á—Ç–æ–±—ã:
    # - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ–ª–Ω–æ—Ç—É –¥–∞–Ω–Ω—ã—Ö
    # - –Ω–µ —Å–º–µ—à–∏–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –¥—Ä—É–≥–∏–º–∏ –∑–∞–ø—É—Å–∫–∞–º–∏
    def get_all_tasks_for_domain(domain_name: str) -> List[str]:
        possible_paths = [
            results_dir.parent / "tau2" / "domains" / domain_name / "tasks.json",
            results_dir.parent / "domains" / domain_name / "tasks.json",
            Path("data/tau2/domains") / domain_name / "tasks.json",
        ]
        for path in possible_paths:
            if path.exists():
                try:
                    with open(path, "r", encoding="utf-8") as f:
                        tasks_data = json.load(f)
                    if isinstance(tasks_data, list):
                        return [t["id"] for t in tasks_data if "id" in t]
                    if isinstance(tasks_data, dict):
                        tasks_list = tasks_data.get("tasks", [])
                        return [t["id"] for t in tasks_list if "id" in t]
                except Exception:
                    continue
        return []

    def is_complete_result_file(
        path: Path, task_id: str
    ) -> tuple[bool, int, str | None]:
        if not path.exists():
            return (False, 0, "missing")
        try:
            with open(path, "r", encoding="utf-8") as f:
                data = json.load(f)
            sims = data.get("simulations", [])
            task_ids = {s.get("task_id") for s in sims if isinstance(s, dict)}
            if sims and task_id not in task_ids:
                return (False, len(sims), f"wrong task_id {task_ids}")
            if len(sims) < args.num_trials:
                return (False, len(sims), "incomplete")
            return (True, len(sims), None)
        except Exception as e:
            return (False, 0, f"unreadable: {e}")

    expected_files: list[tuple[Path, str]] = []
    for domain in args.domains:
        domain_tasks = domains_dict.get(domain) or get_all_tasks_for_domain(domain)
        if not domain_tasks:
            print(f"‚ö†Ô∏è  No tasks found for domain {domain}")
            continue

        for model in args.models:
            model_id = _model_id_for_results(model)
            file_model = _sanitize_model_for_filename(model_id)
            for temp in args.temperatures:
                for task_id in domain_tasks:
                    stem = f"paper_results_{domain}_{file_model}_T{temp}_{task_id}"
                    expected_files.append((results_dir / f"{stem}.json", task_id))

    missing_or_incomplete: list[str] = []
    selected_result_files: list[Path] = []
    seen_paths: set[str] = set()

    for path, task_id in expected_files:
        ok, sim_count, reason = is_complete_result_file(path, task_id)
        if ok:
            key = str(path)
            if key not in seen_paths:
                selected_result_files.append(path)
                seen_paths.add(key)
        else:
            missing_or_incomplete.append(
                f"{path.name} ({reason}, {sim_count}/{args.num_trials})"
            )

    print(
        f"Expected files: {len(expected_files)} | complete: {len(selected_result_files)} | missing/incomplete: {len(missing_or_incomplete)}"
    )
    if missing_or_incomplete and not args.allow_incomplete:
        print("\n‚ùå Dataset is incomplete; not updating tables/figs/template.")
        print("   To force generation anyway, pass --allow-incomplete")
        print("\nFirst missing/incomplete files:")
        for line in missing_or_incomplete[:20]:
            print(f"  - {line}")
        return

    # –®–∞–≥ 2: –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (—Ç–æ–ª—å–∫–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ result files)
    metrics = process_all_results(results_dir, result_files=selected_result_files)

    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –≤ JSON –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    metrics_file = results_dir / "summary_metrics.json"
    with open(metrics_file, "w") as f:
        json.dump(metrics, f, indent=2, default=str)
    print(f"Metrics saved to {metrics_file}")

    # –®–∞–≥ 3: –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–∞–±–ª–∏—Ü—ã LaTeX
    print("\n" + "=" * 80)
    print("–®–ê–ì 3: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è LaTeX —Ç–∞–±–ª–∏—Ü")
    print("=" * 80)
    result_files = selected_result_files

    template_dir = args.template_path.parent
    detailed_table_path = template_dir / "detailed_metrics_table.tex"
    aggregated_table_path = template_dir / "aggregated_table.tex"
    model_domain_table_path = template_dir / "model_domain_table.tex"
    significance_table_path = template_dir / "significance_table.tex"
    temp_significance_table_path = template_dir / "temperature_significance_table.tex"

    generate_detailed_metrics_table_latex(
        result_files, args.domains, detailed_table_path
    )

    # Note: this table aggregates across mixed configs; kept for reference.
    generate_aggregated_table_latex(result_files, args.domains, aggregated_table_path)

    generate_model_domain_table_latex(
        result_files,
        args.domains,
        [_normalize_model_name(m) for m in args.models],
        [float(t) for t in args.temperatures],
        model_domain_table_path,
    )

    generate_significance_table_latex(
        result_files,
        args.domains,
        [float(t) for t in args.temperatures],
        model_a="gpt-4o",
        model_b="gpt-4o-mini",
        output_path=significance_table_path,
    )

    generate_temperature_significance_table_latex(
        result_files,
        args.domains,
        [_normalize_model_name(m) for m in args.models],
        [float(t) for t in args.temperatures],
        output_path=temp_significance_table_path,
    )

    print(
        "Tables generated: "
        f"{detailed_table_path}, {aggregated_table_path}, "
        f"{model_domain_table_path}, {significance_table_path}, {temp_significance_table_path}"
    )

    # –®–∞–≥ 4: –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
    if not args.skip_visualizations:
        print("\n" + "=" * 80)
        print("–®–ê–ì 4: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π")
        print("=" * 80)
        figs_dir = template_dir / "figs"
        generate_visualizations(metrics, figs_dir)
    else:
        print("–ü—Ä–æ–ø—É—Å–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π (--skip-visualizations)")
        figs_dir = template_dir / "figs"

    # –®–∞–≥ 5: –û–±–Ω–æ–≤–∏—Ç—å template.tex
    print("\n" + "=" * 80)
    print("–®–ê–ì 5: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ template.tex")
    print("=" * 80)
    update_template_tex(
        args.template_path,
        detailed_table_path,
        model_domain_table_path,
        significance_table_path,
        temp_significance_table_path,
        figs_dir,
    )

    # –®–∞–≥ 6: –°–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞—Ç—å PDF
    if args.compile_pdf:
        print("\n" + "=" * 80)
        print("–®–ê–ì 6: –ö–æ–º–ø–∏–ª—è—Ü–∏—è PDF")
        print("=" * 80)
        compile_pdf(args.template_path)
    else:
        print("\n–î–ª—è –∫–æ–º–ø–∏–ª—è—Ü–∏–∏ PDF –∑–∞–ø—É—Å—Ç–∏—Ç–µ:")
        print(
            f"  cd docs/paper_template && pdflatex -interaction=nonstopmode -halt-on-error template.tex"
        )

    print("\n" + "=" * 80)
    print("–ì–û–¢–û–í–û!")
    print("=" * 80)


if __name__ == "__main__":
    main()
